[{"uri":"/01trainmodel.html","title":"模型训练","tags":[],"description":"","content":"Mask R-CNN是一个实例分割（Instance segmentation）算法，可以用来做“目标检测”、“目标实例分割”、“目标关键点检测”。\n下面介绍如何使用amazon sagemaker创建mask rcnn的训练和模型部署。\n"},{"uri":"/02deploymodlea.html","title":"模型A 部署和使用","tags":[],"description":"","content":"模型A是车辆判别模型 ， 基于预训练的目标分割的车辆判别模型，判断图中是否有车。\n本模块通过一系列示例来演示模型A的部署和使用方法，您将了解模型A的打包部署步骤。\n同时，您可以了解如何通过脚本和客户端程序完成：数据准备，模型A调用，数据后处理的完整过程。\n"},{"uri":"/01trainmodel/0101setup.html","title":"环境搭建","tags":[],"description":"","content":"环境 AWS 账户 要完成本次研讨会，您需要一个 AWS 账户，以及该账户中的一个 AWS IAM 用户至少具有以下 AWS 服务的完全权限：\n AWS IAM Amazon S3 Amazon SageMaker  使用您自己的账户：本研讨会中的代码和说明假定一次只有一名学生正在使用给定的 AWS 账户。如果您尝试与其他学生共享帐户，您将遇到某些资源的命名冲突。您可以通过为由于冲突而无法创建的资源附加唯一后缀来解决这些问题，但说明不提供有关使此工作所需的更改的详细信息。为此研讨会使用个人账户或创建新的 AWS 账户，而不是使用组织的账户，以确保您能够完全访问必要的服务，并确保您不会留下研讨会的任何资源。\n成本：如果您的账户不到 12 个月，您将在此研讨会中启动的部分资源（但不是全部）有资格享受 AWS 免费套餐。有关更多详细信息，请参阅 AWS 免费套餐页面。免费套餐不覆盖的资源示例是某些研讨会中使用的 ml.m5.xlarge 笔记本实例。为了避免在完成研讨会后对终端节点和其他资源产生费用，请参阅清理模块。\nAWS 区域 目前，SageMaker 并非在所有 AWS 区域都可用。因此，我们建议在以下受支持的 AWS 区域之一举行此研讨会：\n 由西云数据运营的AWS(宁夏)区域 由光环新网运营的AWS(北京)区域  选择区域后，您应该为此研讨会创建所有资源，包括一个新的 Amazon S3 存储桶和一个新的 SageMaker 笔记本实例。在开始之前，请确保从 AWS 控制台右上角的下拉列表中选择您的区域。\n浏览器 我们建议您使用最新版本的 Chrome 或火狐浏览器来完成本次研讨会。\nAWS 命令行界面 要完成某些研讨会模块，您需要 AWS 命令行界面 (CLI) 和 Bash 环境。您将使用 AWS CLI 与 SageMaker 和其他 AWS 服务进行接口。\n文本编辑器 对于任何需要使用 AWS 命令行界面的研讨会模块（见上文），您还需要一个纯文本编辑器来编写 Bash 脚本。任何插入 Windows 或其他特殊字符的编辑器都可能导致脚本失败。\n"},{"uri":"/02deploymodlea/0201setup.html","title":"环境搭建和验证","tags":[],"description":"","content":"EC2 环境准备 要完成本章节操作步骤，您需要准备一台EC2 实例：\n AMI : Deep Learning AMI (Ubuntu 18.04) Version 39.0 - ami-08773c85de0140def 实例类型： g4dn.xlarge （4C/16G） 存储: 150G  获取模型代码 登录已经启动的 EC2 实例，创建工作目录，并下载代码\nsource activate pytorch_p36 mkdir workshop cd workshop git clone https://github.com/jackie930/amazon-sagemaker-mask-r-cnn-pytorch 配置AK/SK 使用“aws configure” 命令配置AK/SK\naws configure AWS Access Key ID [None]: ******************** AWS Secret Access Key [None]: **************************************** Default region name [None]: cn-northwest-1 Default output format [None]: 注意 请将“*******” 替换为您AWS 帐号的Access Key ID 和 AWS Secret Access Key\n检查模型文件 检查一下两个模型文件(.pth) 是否已经存在\nls -la *pth -rw-r--r-- 1 ubuntu ubuntu 178090079 Feb 2 23:31 maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth -rw-r--r-- 1 ubuntu ubuntu 44793465 Feb 2 23:25 model.pth 修改Dockerfile 如需要使用本地GPU EC2实例部署和使用模型A，需要修改Dockerfile\n 修改gpu基础镜像：  ARG REGISTRY_URI # FROM ${REGISTRY_URI}/pytorch-inference:1.5.0-cpu-py36-ubuntu16.04 FROM ${REGISTRY_URI}/pytorch-inference:1.5.0-gpu-py3 增加以下安装命令：   RUN pip install torchvision GPUtil -i https://opentuna.cn/pypi/web/simple 修改复制内容  #COPY * /opt/program/ COPY maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth /root/.cache/torch/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth COPY model.pth /opt/program/ COPY predictor.py /opt/program/ COPY serve.py /opt/program/ COPY wsgi.py /opt/program/ COPY nginx.conf /opt/program/ WORKDIR /opt/program 修改模型代码 import torchvision import PIL import codecs import copy import re import base64 from io import BytesIO  data = flask.request.data.decode('utf-8') # data = json.loads(data) # bucket = data['bucket'] # image_uri = data['image_uri'] img_data = data # download_file_name = image_uri.split('/')[-1] # print (\u0026quot;\u0026lt;\u0026lt;\u0026lt;\u0026lt;download_file_name \u0026quot;, download_file_name) # #download_file_name = './test.jpg' # s3_client.download_file(bucket, image_uri, download_file_name) # print('Download finished!') # inference and send result to RDS and SQS print('Start to inference:') if torch.cuda.is_available(): print(\u0026quot;==\u0026gt; Using cuda\u0026quot;) else: print(\u0026quot;==\u0026gt; Using cpu\u0026quot;) device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')  input_size = 224 trans2 = transforms.Compose([ transforms.Resize(input_size), transforms.CenterCrop(input_size), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]) # image = PIL.Image.open(download_file_name) img_data = data image = base64_to_image(img_data) def base64_to_image(base64_str, image_path=None): base64_data = re.sub('^data:image/.+;base64,', '', base64_str) byte_data = base64.b64decode(base64_data) image_data = BytesIO(byte_data) img = PIL.Image.open(image_data) if image_path: img.save(image_path) return img Build Docker image ./build_local.sh 执行成功后检查image 并启动容器\ndocker images REPOSITORY TAG IMAGE ID CREATED SIZE car-filter latest 44e85c202503 15 hours ago 9.54GB 启动容器\nnvidia-docker run -d -p 8080:8080 --env AWS_DEFAULT_REGION=cn-northwest-1 car-filter 数据准备 将模拟测试数据上传到 EC2 \u0026ldquo;sample_20210202\u0026rdquo; 目录\nfind sample_20210202/ sample_20210202/ sample_20210202/标的定损-本田 sample_20210202/标的定损-本田/现场查勘照片 sample_20210202/标的定损-本田/现场查勘照片/外观照片 (10)29.jpg sample_20210202/标的定损-本田/现场查勘照片/内杠损失 (1)16.jpg sample_20210202/标的定损-本田/现场查勘照片/人车合影19.jpg .... sample_20210202/三者定损-江铃江特 sample_20210202/三者定损-江铃江特/现场查勘照片 sample_20210202/三者定损-江铃江特/现场查勘照片/现场查勘照片15.jpg sample_20210202/三者定损-江铃江特/现场查勘照片/现场查勘照片10.jpg sample_20210202/三者定损-江铃江特/现场查勘照片/现场查勘照片14.jpg ... 创建输出目录 “output”\nmkdir output python create_output.py -input sample_20210202/ -output output/ ls output/ out_car out_err1 out_err2 out_no_car out_not_pic out_parts 测试调用模型 python run_filter.py -input \u0026quot;sample_20210202/\u0026quot; -output \u0026quot;output\u0026quot; -api \u0026quot;http://localhost:8080/invocations\u0026quot; 导出 / 导入 image 执行以下命令导出image\ndocker save car-filter -o car-filter.tar 将tar 文件复制到另一台服务器，执行以下命令，装载镜像\ndocker load \u0026lt; car-filter.tar "},{"uri":"/01trainmodel/0101setup/010101jupyter.html","title":"创建SageMaker笔记本实例","tags":[],"description":"","content":"创建笔记本实例 SageMaker 提供无需设置的托管Jupyter Notebook，因此您可以立即开始处理您的训练数据集。只需在 SageMaker 控制台中单击几下，您就可以创建完全托管的笔记本实例，预先加载了用于机器学习的有用库。您只需添加您的数据。\n首先，您将创建将在整个研讨会中使用的 Amazon S3 存储桶。然后，您将创建一个 SageMaker 笔记本实例，该实例将用于其他研讨会模块。\n创建 S3 存储桶 SageMaker 通常使用 S3 作为数据和模型工件的存储。在此步骤中，您将为此目的创建 S3 存储桶。要开始，请登录 AWS 管理控制台 https://console.amazonaws.cn/。\n请记住，您的存储桶名称必须在所有区域和客户中具有全球唯一性。我们建议使用像 spot-bot-exampledata-cn-northwest-1-123456789012 这样的名字（这里的\u0026quot;123456789012\u0026quot;代表您的账户ID）。如果您收到存储桶名称已存在的错误信息，请尝试添加其他数字或字符，直到找到未使用的名称。\n  在 AWS 管理控制台中，选择服务，然后在存储下选择 S3。\n  选择创建存储桶\n  为您的存储桶提供全局唯一的名称，例如 “spot-bot-exampledata-cn-northwest-1-123456789012”。(请参考使用机器人章节，【使用 cloudformation 创建 EC2 并创建 S3 Bucket】)\n  从下拉列表中选择您选择用于此研讨会的区域。\n  在对话框左下角选择创建，而不选择要从中复制设置的存储桶。\n  启动笔记本实例   在 AWS 管理控制台的右上角，确认您位于所需的 AWS 区域。选择由西云数据运营的AWS(宁夏)区域或由光环新网运营的AWS(北京)区域。\n  点击所有服务列表中的亚马逊 SageMaker。这将带您访问亚马逊 SageMaker 控制台主页。\n  要创建新的笔记本实例，请转到笔记本实例，然后单击浏览器窗口顶部的创建笔记本实例按钮。  在笔记本实例名称文本框中键入mldev，然后选择 ml.t3.medium 作为笔记本实例类型。  选择名称为SpotBot的VPC，并选择名称为SpotBot-PublicSubnet2的子网。  对于 IAM 角色，选择创建新角色，然后在生成的弹出模式中，选择您指定的 S3 存储桶下的任意 S3 存储桶。单击创建角色。  在IAM中选择角色，在角色列表中选择刚刚创建的SageMaker-ExecutionRole，并添加AmazonEC2ContainerRegistryFullAccess Policy。  访问笔记本电脑实例  等待服务器状态更改为 InService。这将需要几分钟，可能最多 10 分钟，但可能更少。  单击 “打开”。您现在将看到您的笔记本实例的 Jupyter 主页。  "},{"uri":"/01trainmodel/0103semanticbot.html","title":" 模型训练","tags":[],"description":"","content":"这里，我们来介绍一下如何使用sagemaker训练一个目标分割型。共分为以下几步：\n 下载数据 下载代码 本地训练 模型训练日志 查看结果  下载代码 cd SageMaker \u0026amp;\u0026amp; git clone https://github.com/jackie930/amazon-sagemaker-mask-r-cnn-pytorch.git 下载数据 cd amazon-sagemaker-mask-r-cnn-pytorch mkdir data \u0026amp;\u0026amp; cd data #download file (todo: change access) wget s3://lianbao-mask-rcnn/modelb/modelc.zip #unzip unzip modelc.zip 运行后，你可以看到对应的文件目录\n-|--label |--pic |--jingbiao.json 本地训练测试 模型c\nsource activate pytorch_p36 pip install pycocotools tensorboard cd ../container/mask_r_cnn python local_train.py \\  --root_train_data=\u0026#39;../../data/modelc\u0026#39; \\  --model_type=\u0026#39;modelc_sub\u0026#39; \\  --num_epochs=2 \\  --save_path=\u0026#39;../../models/modelc\u0026#39; 训练日志 训练结果 模型产生的结果目录中，可以看到模型在测试集上的表现\n   IoU metric: bbox 结果     Average Precision (AP) @[ IoU=0.50:0.95 area= all maxDets=100 ] 0.464   Average Precision (AP) @[ IoU=0.50 area= all maxDets=100 ] 0.646   Average Precision (AP) @[ IoU=0.75 area= all maxDets=100 ] 0.526   Average Precision (AP) @[ IoU=0.50:0.95 area= small maxDets=100 ] 0.118   Average Precision (AP) @[ IoU=0.50:0.95 area=medium maxDets=100 ] 0.261   Average Precision (AP) @[ IoU=0.50:0.95 area= large maxDets=100 ] 0.572   Average Recall (AR) @[ IoU=0.50:0.95 area= all maxDets= 1 ] 0.481   Average Recall (AR) @[ IoU=0.50:0.95 area= all maxDets= 10 ] 0.658   Average Recall (AR) @[ IoU=0.50:0.95 area= all maxDets=100 ] 0.658   Average Recall (AR) @[ IoU=0.50:0.95 area= small maxDets=100 ] 0.188   Average Recall (AR) @[ IoU=0.50:0.95 area=medium maxDets=100 ] 0.470   Average Recall (AR) @[ IoU=0.50:0.95 area= large maxDets=100 ] 0.780    "},{"uri":"/categories.html","title":"Categories","tags":[],"description":"","content":""},{"uri":"/tags.html","title":"Tags","tags":[],"description":"","content":""},{"uri":"/","title":"联保智能车损 datalab","tags":[],"description":"","content":"概述 本次分为几个部分\n 基于maskrcnn的目标检测模型训练 模型A （车损分类过滤）的部署  本次 workshop 前提 本次 workshop 建议在 宁夏 Region 使用。为了演示方便，所以本 workshop 所有的演示都会以宁夏 Region 为例。\n"}]